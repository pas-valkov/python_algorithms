{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "def batch_generator(X, y, shuffle=True, batch_size=1):\n",
    "    \"\"\"\n",
    "    Гератор новых батчей для обучения\n",
    "    X          - матрица объекты-признаки\n",
    "    y_batch    - вектор ответов\n",
    "    shuffle    - нужно ли случайно перемешивать выборку\n",
    "    batch_size - размер батча ( 1 это SGD, > 1 mini-batch GD)\n",
    "    Генерирует подвыборку для итерации спуска (X_batch, y_batch)\n",
    "    \"\"\"\n",
    "    size = X.shape[0]\n",
    "    if shuffle:\n",
    "        pos = np.random.permutation(np.arange(size))\n",
    "    else:\n",
    "        pos = np.arange(size)\n",
    "\n",
    "    for i in range(0, size - batch_size + 1, batch_size):\n",
    "        X_batch = X[pos[i: i + batch_size]]\n",
    "        y_batch = y[pos[i: i + batch_size]]\n",
    "        yield (X_batch, y_batch)\n",
    "\n",
    "# Теперь можно сделать генератор по данным ()\n",
    "#  my_batch_generator = batch_generator(X, y, shuffle=True, batch_size=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Вычисляем значение сигмоида.\n",
    "    X - выход линейной модели\n",
    "    \"\"\"\n",
    "    sigm_value_x = 1 / (1 + np.exp(-x))\n",
    "    return sigm_value_x\n",
    "\n",
    "\n",
    "class MySGDClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, batch_generator, batch_size=1,\n",
    "                 C=1, alpha=0.01,\n",
    "                 max_epoch=10, model_type='lin_reg'):\n",
    "        \"\"\"\n",
    "        batch_generator -- функция генератор, которой будем создавать батчи\n",
    "        C - коэф. регуляризации\n",
    "        alpha - скорость спуска\n",
    "        max_epoch - максимальное количество эпох\n",
    "        model_type - тим модели, lin_reg или log_reg\n",
    "        \"\"\"\n",
    "\n",
    "        self.C = C\n",
    "        self.alpha = alpha\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_generator = batch_generator\n",
    "        self.errors_log = {'iter': [], 'loss': []}\n",
    "        self.model_type = model_type\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def calc_loss(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем функцию потерь по батчу\n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        if self.model_type == \"lin_reg\":\n",
    "            dot = np.dot(X_batch, self.weights)\n",
    "            loss = np.sum((dot - y_batch) ** 2) / X_batch.shape[0]\n",
    "        elif self.model_type == \"log_reg\":\n",
    "            dot = sigmoid(np.dot(X_batch, self.weights))\n",
    "            temp1 = y_batch * np.log(dot) + (1 - y_batch) * np.log(1 - dot)\n",
    "            loss = -np.sum(temp1) / X_batch.shape[0]\n",
    "        loss += (np.sum(self.weights ** 2) / self.C)\n",
    "        return loss\n",
    "\n",
    "    def calc_loss_grad(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем градиент функции потерь по батчу (то что Вы вывели в задании 1)\n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        if self.model_type == \"lin_reg\":\n",
    "            temp1 = np.dot(X_batch, self.weights)\n",
    "            loss_grad = 2 * (np.dot(temp1 - y_batch,\n",
    "                                    X_batch)) / X_batch.shape[0]\n",
    "        elif self.model_type == \"log_reg\":\n",
    "            temp1 = sigmoid(np.dot(X_batch, self.weights))\n",
    "            loss_grad = -np.dot(y_batch - temp1, X_batch) / X_batch.shape[0]\n",
    "        loss_grad += (2 * self.weights / self.C)\n",
    "        return loss_grad\n",
    "\n",
    "    def update_weights(self, new_grad):\n",
    "        \"\"\"\n",
    "        Обновляем вектор весов\n",
    "        new_grad - градиент по батчу\n",
    "        \"\"\"\n",
    "        self.weights -= self.alpha * new_grad\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Обучение модели\n",
    "        X - матрица объекты-признаки\n",
    "        y - вектор ответов\n",
    "        '''\n",
    "        X_upd = np.insert(X, 0, 1, axis=1)\n",
    "        self.weights = np.random.randn(X_upd.shape[1])\n",
    "        \n",
    "        for n in range(0, self.max_epoch):\n",
    "            new_epoch_generator = self.batch_generator(\n",
    "                X_upd, y, batch_size=self.batch_size)\n",
    "            \n",
    "            for batch_num, new_batch in enumerate(new_epoch_generator):\n",
    "                X_batch = new_batch[0]\n",
    "                y_batch = new_batch[1]\n",
    "                batch_grad = self.calc_loss_grad(X_batch, y_batch)\n",
    "                self.update_weights(batch_grad)\n",
    "\n",
    "                batch_loss = self.calc_loss(X_batch, y_batch)\n",
    "                self.errors_log['iter'].append(batch_num)\n",
    "                self.errors_log['loss'].append(batch_loss)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Предсказание класса\n",
    "        X - матрица объекты-признаки\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        '''\n",
    "        X_upd = np.insert(X, 0, 1, axis=1)\n",
    "        if self.model_type == \"lin_reg\":\n",
    "            y_hat = np.dot(X_upd, self.weights)\n",
    "        elif self.model_type == \"log_reg\":\n",
    "            y_hat = sigmoid(np.dot(X_upd, self.weights))\n",
    "        # Желательно здесь использовать матричные операции\n",
    "        # между X и весами, например, numpy.dot\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Боевое применение (3  балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import pymorphy2\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('russian')\n",
    "stemmer = nltk.stem.SnowballStemmer('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "stop_words.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def title_preprocessing(title, stop_words, preprocessing_type='stemming'):\n",
    "    title = stop_words_remove(title.strip().split(), stop_words, preprocessing_type)\n",
    "    return ' '.join(title)\n",
    "\n",
    "def stop_words_remove(title_words, stop_words, preprocessing_type='stemming'):\n",
    "    #new_title = str()\n",
    "    new_title = []\n",
    "    for i in title_words:\n",
    "        i = i.strip(' !?@#$^&*\"\\'()_«»<>-+={}[]/\\.,:;') #%\n",
    "        if i in stop_words:\n",
    "            pass\n",
    "        else:\n",
    "            if preprocessing_type == 'stemming':\n",
    "                i = title_stemming(i)\n",
    "            else:\n",
    "                i = title_lemming(i)\n",
    "            if len(i) == 1:   # 11879 - problem\n",
    "                pass\n",
    "            else:\n",
    "                new_title.append(i)\n",
    "    return new_title\n",
    "\n",
    "def title_stemming(title_words):\n",
    "    return stemmer.stem(title_words)\n",
    "\n",
    "def title_lemming(title):\n",
    "    return morph.parse(title)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28026\n"
     ]
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "with open('docs_titles.tsv', encoding='utf-8') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            #title = data[1]\n",
    "            title = title_preprocessing(data[1], stop_words, preprocessing_type='lemming')\n",
    "        doc_to_title[doc_id] = title\n",
    "print(len(doc_to_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "doc_to_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train_groups.csv')\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(train_data)):\n",
    "    new_doc = train_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    target = new_doc['target']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 2) (11690,) (11690,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse.csr import csr_matrix #need this if you want to save tfidf_matrix\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def get_group_articles(data):\n",
    "    rez = []\n",
    "    for i in data:\n",
    "        rez.append(i[1])\n",
    "    return rez\n",
    "\n",
    "\n",
    "y_train = []\n",
    "X_train = []\n",
    "groups_train = []\n",
    "for new_group in traingroups_titledata:\n",
    "    docs = traingroups_titledata[new_group]\n",
    "\n",
    "    tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1),\n",
    "                         min_df=0, stop_words=None, sublinear_tf=True)\n",
    "    all_group_articles = get_group_articles(docs)\n",
    "    tfidf_matrix = tf.fit_transform(all_group_articles).toarray()\n",
    "\n",
    "#     print(tfidf_matrix.shape)\n",
    "    \n",
    "    u, s, vt = np.linalg.svd(tfidf_matrix.T)\n",
    "#     print(u.shape, s.shape, vt.shape)\n",
    "#     print(vt[:2])\n",
    "\n",
    "#     plt.scatter(vt[:1], vt[1:2])\n",
    "#     plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "#     y_temp = []\n",
    "#     for (doc_id, title, target_id) in (docs):\n",
    "#         if target_id == 1:\n",
    "#             y_temp.append('green')\n",
    "#         else:\n",
    "#             y_temp.append('blue')\n",
    "\n",
    "#     plt.scatter(vt[0:1], vt[1:2], color=y_temp)\n",
    "#     plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     svd = TruncatedSVD(n_components=2, n_iter=7)\n",
    "#     svd.fit(tfidf_matrix.T)\n",
    "    \n",
    "#     print(svd.singular_values_)\n",
    "    \n",
    "#     input()\n",
    "#     continue\n",
    "\n",
    "    \n",
    "    for k, (doc_id, title, target_id) in enumerate(docs):\n",
    "        y_train.append(target_id)\n",
    "        groups_train.append(new_group)\n",
    "#         all_dist = []\n",
    "        \n",
    "        \n",
    "        X_train.append((vt[0, k], vt[1, k]))\n",
    "#         X_train.append((vt[:, k]))\n",
    "\n",
    "\n",
    "#         svd = TruncatedSVD(n_components=2, n_iter=7)\n",
    "#         svd.fit(tfidf_matrix)\n",
    "        \n",
    "#         for j in range(0, len(docs)):\n",
    "#             if k == j:\n",
    "#                 continue\n",
    "\n",
    "#             all_dist.append(euclidean(tfidf_matrix[k], tfidf_matrix[j]))\n",
    "#         X_train.append((sorted(all_dist, reverse=False))[0:10])\n",
    "        \n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "groups_train = np.array(groups_train)\n",
    "print (X_train.shape, y_train.shape, groups_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.87205025e-01, -1.62220702e-01],\n",
       "       [-1.18225148e-01,  2.93127514e-01],\n",
       "       [-1.23440673e-01,  2.15946873e-02],\n",
       "       ...,\n",
       "       [ 8.20404111e-19,  1.30868241e-19],\n",
       "       [-4.47894396e-02,  1.24900090e-16],\n",
       "       [-1.08591198e-04,  1.17961196e-16]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.872050e-01</td>\n",
       "      <td>-1.622207e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.182251e-01</td>\n",
       "      <td>2.931275e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.234407e-01</td>\n",
       "      <td>2.159469e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>4.440892e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.220658e-01</td>\n",
       "      <td>-1.423748e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6.788986e-02</td>\n",
       "      <td>4.821970e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-9.643598e-02</td>\n",
       "      <td>-3.132782e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.282126e-01</td>\n",
       "      <td>5.244821e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.771822e-02</td>\n",
       "      <td>-9.474293e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.085910e-02</td>\n",
       "      <td>2.033767e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.346842e-01</td>\n",
       "      <td>-6.272770e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-7.296907e-02</td>\n",
       "      <td>6.502292e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-3.391715e-03</td>\n",
       "      <td>1.157417e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-4.050179e-02</td>\n",
       "      <td>-1.374906e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-4.367281e-02</td>\n",
       "      <td>-3.192830e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.498775e-02</td>\n",
       "      <td>6.045596e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.133059e-01</td>\n",
       "      <td>-5.096280e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.577722e-30</td>\n",
       "      <td>1.033976e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.017702e-01</td>\n",
       "      <td>2.310453e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.516368e-02</td>\n",
       "      <td>-1.838868e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.832983e-02</td>\n",
       "      <td>5.047809e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-3.995947e-02</td>\n",
       "      <td>7.686230e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-9.723057e-02</td>\n",
       "      <td>2.957056e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-8.759067e-02</td>\n",
       "      <td>1.163237e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-4.908341e-02</td>\n",
       "      <td>4.303177e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-2.387694e-02</td>\n",
       "      <td>-1.863855e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.098546e-01</td>\n",
       "      <td>-1.531352e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.419386e-02</td>\n",
       "      <td>2.358856e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.903729e-01</td>\n",
       "      <td>-1.497609e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.277409e-01</td>\n",
       "      <td>-8.964910e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11660</th>\n",
       "      <td>-7.325605e-03</td>\n",
       "      <td>3.330669e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11661</th>\n",
       "      <td>-4.156431e-03</td>\n",
       "      <td>3.469447e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11662</th>\n",
       "      <td>-8.164114e-03</td>\n",
       "      <td>-1.741662e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11663</th>\n",
       "      <td>-3.082139e-01</td>\n",
       "      <td>-3.885781e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11664</th>\n",
       "      <td>-2.353331e-01</td>\n",
       "      <td>-7.910339e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11665</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.883189e-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11666</th>\n",
       "      <td>2.278528e-18</td>\n",
       "      <td>1.263023e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11667</th>\n",
       "      <td>-1.398847e-02</td>\n",
       "      <td>-1.304512e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11668</th>\n",
       "      <td>-8.904418e-04</td>\n",
       "      <td>3.601286e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11669</th>\n",
       "      <td>-4.725958e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11670</th>\n",
       "      <td>-2.653134e-01</td>\n",
       "      <td>7.563394e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11671</th>\n",
       "      <td>-2.978139e-01</td>\n",
       "      <td>-1.318390e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11672</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.472136e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11673</th>\n",
       "      <td>2.237994e-18</td>\n",
       "      <td>-8.111508e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11674</th>\n",
       "      <td>-2.697184e-04</td>\n",
       "      <td>2.366163e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11675</th>\n",
       "      <td>-6.440765e-04</td>\n",
       "      <td>-1.457168e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11676</th>\n",
       "      <td>-2.546616e-02</td>\n",
       "      <td>-2.248202e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11677</th>\n",
       "      <td>-2.457270e-19</td>\n",
       "      <td>-7.802664e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11678</th>\n",
       "      <td>-1.065166e-02</td>\n",
       "      <td>7.745540e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11679</th>\n",
       "      <td>-6.658873e-06</td>\n",
       "      <td>-1.387779e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11680</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.472136e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11681</th>\n",
       "      <td>-6.185268e-02</td>\n",
       "      <td>-5.204170e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11682</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11683</th>\n",
       "      <td>-1.556220e-03</td>\n",
       "      <td>-9.649399e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11684</th>\n",
       "      <td>-1.698206e-18</td>\n",
       "      <td>9.848699e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11685</th>\n",
       "      <td>-3.165446e-18</td>\n",
       "      <td>-9.462120e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11686</th>\n",
       "      <td>-2.355681e-18</td>\n",
       "      <td>-1.540744e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11687</th>\n",
       "      <td>8.204041e-19</td>\n",
       "      <td>1.308682e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11688</th>\n",
       "      <td>-4.478944e-02</td>\n",
       "      <td>1.249001e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11689</th>\n",
       "      <td>-1.085912e-04</td>\n",
       "      <td>1.179612e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11690 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1\n",
       "0     -2.872050e-01 -1.622207e-01\n",
       "1     -1.182251e-01  2.931275e-01\n",
       "2     -1.234407e-01  2.159469e-02\n",
       "3      5.551115e-17  4.440892e-16\n",
       "4     -2.220658e-01 -1.423748e-01\n",
       "5     -6.788986e-02  4.821970e-03\n",
       "6     -9.643598e-02 -3.132782e-03\n",
       "7     -1.282126e-01  5.244821e-02\n",
       "8     -8.771822e-02 -9.474293e-03\n",
       "9     -1.085910e-02  2.033767e-02\n",
       "10    -1.346842e-01 -6.272770e-02\n",
       "11    -7.296907e-02  6.502292e-02\n",
       "12    -3.391715e-03  1.157417e-03\n",
       "13    -4.050179e-02 -1.374906e-02\n",
       "14    -4.367281e-02 -3.192830e-03\n",
       "15    -2.498775e-02  6.045596e-02\n",
       "16    -1.133059e-01 -5.096280e-02\n",
       "17     1.577722e-30  1.033976e-25\n",
       "18    -1.017702e-01  2.310453e-01\n",
       "19    -1.516368e-02 -1.838868e-02\n",
       "20    -1.832983e-02  5.047809e-02\n",
       "21    -3.995947e-02  7.686230e-02\n",
       "22    -9.723057e-02  2.957056e-01\n",
       "23    -8.759067e-02  1.163237e-01\n",
       "24    -4.908341e-02  4.303177e-02\n",
       "25    -2.387694e-02 -1.863855e-02\n",
       "26    -1.098546e-01 -1.531352e-02\n",
       "27    -1.419386e-02  2.358856e-02\n",
       "28    -1.903729e-01 -1.497609e-01\n",
       "29    -1.277409e-01 -8.964910e-02\n",
       "...             ...           ...\n",
       "11660 -7.325605e-03  3.330669e-16\n",
       "11661 -4.156431e-03  3.469447e-17\n",
       "11662 -8.164114e-03 -1.741662e-15\n",
       "11663 -3.082139e-01 -3.885781e-16\n",
       "11664 -2.353331e-01 -7.910339e-16\n",
       "11665  0.000000e+00  1.883189e-28\n",
       "11666  2.278528e-18  1.263023e-17\n",
       "11667 -1.398847e-02 -1.304512e-15\n",
       "11668 -8.904418e-04  3.601286e-15\n",
       "11669 -4.725958e-03  0.000000e+00\n",
       "11670 -2.653134e-01  7.563394e-16\n",
       "11671 -2.978139e-01 -1.318390e-16\n",
       "11672  0.000000e+00 -4.472136e-01\n",
       "11673  2.237994e-18 -8.111508e-21\n",
       "11674 -2.697184e-04  2.366163e-15\n",
       "11675 -6.440765e-04 -1.457168e-16\n",
       "11676 -2.546616e-02 -2.248202e-15\n",
       "11677 -2.457270e-19 -7.802664e-23\n",
       "11678 -1.065166e-02  7.745540e-16\n",
       "11679 -6.658873e-06 -1.387779e-17\n",
       "11680  0.000000e+00 -4.472136e-01\n",
       "11681 -6.185268e-02 -5.204170e-16\n",
       "11682  0.000000e+00  0.000000e+00\n",
       "11683 -1.556220e-03 -9.649399e-17\n",
       "11684 -1.698206e-18  9.848699e-21\n",
       "11685 -3.165446e-18 -9.462120e-26\n",
       "11686 -2.355681e-18 -1.540744e-32\n",
       "11687  8.204041e-19  1.308682e-19\n",
       "11688 -4.478944e-02  1.249001e-16\n",
       "11689 -1.085912e-04  1.179612e-16\n",
       "\n",
       "[11690 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).to_csv('feature_tf-idf_svd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "def validation(X_train, y_train, groups_train, N, nn):\n",
    "    validation_size = int(len(set(groups_train)) / N)\n",
    "\n",
    "    val_arr = np.arange(len(set(groups_train)))+1\n",
    "\n",
    "    validation_group_numbers = val_arr[nn * validation_size:\n",
    "                                       (nn + 1) * validation_size]\n",
    "\n",
    "    X_test_validation = []\n",
    "    y_test_validation = []\n",
    "    X_train_validation = []\n",
    "    y_train_validation = []\n",
    "\n",
    "    for i_num, i in enumerate(groups_train):\n",
    "        if i in validation_group_numbers:\n",
    "            X_test_validation.append(X_train[i_num])\n",
    "            y_test_validation.append(y_train[i_num])\n",
    "        else:\n",
    "            X_train_validation.append(X_train[i_num])\n",
    "            y_train_validation.append(y_train[i_num])\n",
    "\n",
    "    X_test_validation = np.array(X_test_validation)\n",
    "    y_test_validation = np.array(y_test_validation)\n",
    "    X_train_validation = np.array(X_train_validation)\n",
    "    y_train_validation = np.array(y_train_validation)\n",
    "\n",
    "    return X_test_validation, y_test_validation, \\\n",
    "        X_train_validation, y_train_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "#a_all = [0.45, 0.5, 0.55]\n",
    "a_all = np.linspace(0.45, 0.55, 5)\n",
    "c_all = [50]\n",
    "e_all = [50, 100]\n",
    "threshold = np.linspace(0.3, 0.4, 10)\n",
    "N = 5\n",
    "\n",
    "best = 0.\n",
    "params = (0., 0., 0., \"\", 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Python37\\lib\\site-packages\\ipykernel_launcher.py:47: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Program Files (x86)\\Python37\\lib\\site-packages\\ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47500000000000003, 50, 100, 'log_reg', 0.32222222222222224) 0.6935435416270745\n"
     ]
    }
   ],
   "source": [
    "params_all = itertools.product(a_all, c_all, e_all, threshold)\n",
    "\n",
    "for (a, c, e, th) in params_all:\n",
    "    sum_score = 0\n",
    "    for i in range(N):\n",
    "\n",
    "        X_test_validation, y_test_validation,\\\n",
    "            X_train_validation, y_train_validation = validation(X_train_norm,\n",
    "                                                                y_train,\n",
    "                                                                groups_train,\n",
    "                                                                N, i)\n",
    "\n",
    "        model = MySGDClassifier(batch_generator=batch_generator, alpha=a,\n",
    "                                C=c, max_epoch=e, model_type='log_reg',\n",
    "                                batch_size=X_train_validation.shape[0])\n",
    "        model.fit(X_train_validation, y_train_validation)\n",
    "\n",
    "        score = f1_score(y_test_validation,\n",
    "                         (model.predict(X_test_validation) > th).astype(int))\n",
    "        sum_score += score\n",
    "    sum_score /= N\n",
    "    if sum_score > best:\n",
    "        best = sum_score\n",
    "        params = (a, c, e, 'log_reg', th)\n",
    "print(params, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16627, 2) (16627,)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('test_groups.csv')\n",
    "\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(test_data)):\n",
    "    new_doc = test_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title))\n",
    "    \n",
    "X_test = []\n",
    "groups_test = []\n",
    "for new_group in traingroups_titledata:\n",
    "    docs = traingroups_titledata[new_group]\n",
    "    \n",
    "    tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 1),\n",
    "                         min_df=0, stop_words=None, sublinear_tf=True)\n",
    "    all_group_articles = get_group_articles(docs)\n",
    "    tfidf_matrix = tf.fit_transform(all_group_articles).toarray()\n",
    "    \n",
    "    u, s, vt = np.linalg.svd(tfidf_matrix.T)\n",
    "    \n",
    "    for k, (doc_id, title) in enumerate(docs):\n",
    "        groups_test.append(new_group)\n",
    "        \n",
    "        X_test.append((vt[0, k], vt[1, k]))\n",
    "        \n",
    "#         all_dist = []\n",
    "#         words = set(title.strip().split())\n",
    "#         for j in range(0, len(docs)):\n",
    "#             if k == j:\n",
    "#                 continue\n",
    "#             doc_id_j, title_j = docs[j]\n",
    "#             words_j = set(title_j.strip().split())\n",
    "#         for j in range(0, len(docs)):\n",
    "#             if k == j:\n",
    "#                 continue\n",
    "\n",
    "#             all_dist.append(euclidean(tfidf_matrix[k], tfidf_matrix[j]))\n",
    "#         X_test.append(sorted(all_dist, reverse=True)[0:10]    )\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "groups_test = np.array(groups_test)\n",
    "print(X_test.shape, groups_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19991686, -0.15895257],\n",
       "       [-0.03976771,  0.17658427],\n",
       "       [-0.12735686, -0.07487224],\n",
       "       ...,\n",
       "       [ 0.1183652 ,  0.00054911],\n",
       "       [ 0.16051067,  0.18262468],\n",
       "       [ 0.08604586, -0.15932115]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_test).to_csv('feature_tf-idf_svd_TEST.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(np.concatenate((X_train, X_test)))\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С лучшими параметрами на валидации сделайте предсказание на тестовом множестве, отправьте его на проверку на платформу kaggle. Убедитесь, что Вы смогли побить public score первого бейзлайна. Если да, то Вы молодец!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47500000000000003, 50, 100, 'log_reg', 0.32222222222222224)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = MySGDClassifier(batch_generator=batch_generator, alpha=params[0],\n",
    "                             C=params[1], max_epoch=params[2],\n",
    "                             model_type=params[3],\n",
    "                             batch_size=X_train.shape[0])\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = 1-(best_model.predict(X_test) > params[4]).astype(int)\n",
    "rez = pd.DataFrame({'pair_id': test_data['pair_id'], 'target': y_predict})\n",
    "rez.to_csv(\"linlogreg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959102664341132"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "402px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
